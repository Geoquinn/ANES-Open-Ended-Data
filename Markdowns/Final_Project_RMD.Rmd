---
title: "Final Project RMD"
output:
  html_notebook: 
    toc: yes
  html_document:
    df_print: paged
  pdf_document: default
editor_options:
  markdown:
    wrap: 72
---

## Code for Random Selection of 200 cases per question

```{r eval=FALSE, include=FALSE}
library(readxl)
anes_2020_4_1_ <- read_excel("anes_2020_4 (1).xlsx")
View(anes_2020_4_1_)
install.packages("openxlsx")

library(dplyr)
# Create 200 Dem Likes Responses

Dem_Likes <- read_excel('anes_2020_4 (1).xlsx', sheet = 'Dem_Likes')

Dem_Likes <- Dem_Likes %>%
  mutate(Dem_Likes = na_if(Dem_Likes, "-1")) %>%  # Replace "-1" with NA
  mutate(Dem_Likes = na_if(Dem_Likes, "-9"))      # Replace "-9" with NA

Dem_Likes <- na.omit(Dem_Likes)

Dem_Likes_200 <- sample_n(Dem_Likes, 200)
library(openxlsx)
write.xlsx(Dem_Likes_200, "Dem_Likes_200.xlsx", rowNames = FALSE)


# Create 200 Dem Dislike Responses

Dem_Dislikes <- read_excel('anes_2020_4 (1).xlsx', sheet = 'Dem_Dislikes')

Dem_Dislikes <- Dem_Dislikes %>%
  mutate(Dem_Dislikes = na_if(Dem_Dislikes, "-1")) %>%  # Replace "-1" with NA
  mutate(Dem_Dislikes = na_if(Dem_Dislikes, "-9"))      # Replace "-9" with NA


Dem_Dislikes <- na.omit(Dem_Dislikes)

Dem_Dislikes_200 <- sample_n(Dem_Dislikes, 200)
library(openxlsx)
write.xlsx(Dem_Dislikes_200, "Dem_Dislikes_200.xlsx", rowNames = FALSE)


# Create 200 Rep_Likes Responses

Rep_Likes <- read_excel('anes_2020_4 (1).xlsx', sheet = 'Rep_Likes')

Rep_Likes <- Rep_Likes %>%
  mutate(Rep_Likes = na_if(Rep_Likes, "-1")) %>%  # Replace "-1" with NA
  mutate(Rep_Likes = na_if(Rep_Likes, "-9"))      # Replace "-9" with NA


Rep_Likes <- na.omit(Rep_Likes)

Rep_Likes_200 <- sample_n(Rep_Likes, 200)

library(openxlsx)
write.xlsx(Rep_Likes_200, "Rep_Likes_200.xlsx", rowNames = FALSE)



# Create 200 Rep_Likes Responses

Rep_Dislikes <- read_excel('anes_2020_4 (1).xlsx', sheet = 'Rep_Dislikes')

Rep_Dislikes <- Rep_Dislikes %>%
  mutate(Rep_Dislikes = na_if(Rep_Dislikes, "-1")) %>%  # Replace "-1" with NA
  mutate(Rep_Dislikes = na_if(Rep_Dislikes, "-9"))      # Replace "-9" with NA


Rep_Dislikes <- na.omit(Rep_Dislikes)

Rep_Dislikes_200 <- sample_n(Rep_Dislikes, 200)

library(openxlsx)
write.xlsx(Rep_Dislikes_200, "Rep_Dislikes_200.xlsx", rowNames = FALSE)
```

Prior selection was completed and compiled into a data frame
"all_four_responses"

## Building the stm from random sampled responses (Model A)

```{r}
library(readxl)
#Generate Dem Likes Sample of 200
anes_data_full <- read_excel("all_four_responses-2.xlsx", sheet = 1)


# Sample 200 responses 
Full_800 <- anes_data_full


# Load necessary libraries
library(dplyr)
library(tm)
library(stm)
library(tidytext)
library(quanteda)
library(tidyr)

# Assuming the data frame is named Full_800 and is already loaded into R
# and it has the columns Dem_Likes, Dem_Dislikes, Rep_Likes, Rep_Dislikes

# Combine the text columns into a single text vector
# Uniting all text responses into one column for each row
Full_800_combined <- Full_800 

# corpus object with the text data
corp_quanteda <- corpus(Full_800_combined$Responses)

# Tokenization and preprocessing
preprocessed_text_data <- tokens(corp_quanteda, 
                                 remove_numbers = TRUE, 
                                 remove_punct = TRUE,
                                 remove_symbols = TRUE) %>%
  tokens_remove(stopwords("en")) %>%
  tokens_wordstem(language = "english") %>%
  tokens_tolower() %>%
  tokens_ngrams(1)

# Create the document-feature matrix (DFM)
topic_dfm <- dfm(preprocessed_text_data) 

# Convert the DFM to the stm format
topic_dfm_stm <- quanteda::convert(topic_dfm, to = "stm")

# Extract the covariates
meta_data <- data.frame(
  PartyId = as.factor(Full_800$V201228), # Factor
  Education = as.factor(Full_800$V201510), # Factor
  Ideology = as.numeric(Full_800$V201201), # Numeric
  GovTrust = as.numeric(Full_800$V201233), # Numeric
  Age = as.numeric(Full_800$V201507x) # Numeric
)
```

## Finding K (Model A)

```{r eval=FALSE, include=FALSE}
# Run searchK to find the optimal number of topics
result <- searchK(documents = topic_dfm_stm$documents, vocab = topic_dfm_stm$vocab, K = 25:45)


# You can plot the results to assess the model fit across different numbers of topics
plot(result, type = "line", ylim = c(0, max(result$heldout)))

# Plot the results
plot(result, metric = "heldout")
plot(result, metric = "semanticcoherence")
plot(result, metric = "residual")

# narrowed results
result_narrowed <- searchK(documents = topic_dfm_stm$documents, vocab = topic_dfm_stm$vocab, K = 30:38)


# You can plot the results to assess the model fit across different numbers of topics
plot(result_narrowed, type = "line", ylim = c(0, max(result$heldout)))

# Plot the results
plot(result_narrowed, metric = "heldout")
plot(result_narrowed, metric = "semanticcoherence")
plot(result_narrowed, metric = "residual")

```

## Model A at 34

```{r}
library(tidytext)
library(tidyr)
library(quanteda)
library(stm)

#Generate Dem Likes Sample of 200
anes_data_full <- read_excel("all_four_responses-2.xlsx", sheet = 1)

# Sample 200 responses 
Full_800 <- anes_data_full


# corpus object with the text data
corp_quanteda <- corpus(Full_800$Responses)

# Tokenization and preprocessing
preprocessed_text_data <- tokens(corp_quanteda, 
                                 remove_numbers = TRUE, 
                                 remove_punct = TRUE,
                                 remove_symbols = TRUE) %>%
  tokens_remove(stopwords("en")) %>%
  tokens_wordstem(language = "english") %>%
  tokens_tolower() %>%
  tokens_ngrams(1)

# Create the document-feature matrix (DFM)
topic_dfm <- dfm(preprocessed_text_data) 


# Extract the covariates
meta_data <- data.frame(
  PartyId = as.factor(Full_800$V201228), # Factor
  Education = as.factor(Full_800$V201510), # Factor
  Ideology = as.numeric(Full_800$V201201), # Numeric
  GovTrust = as.numeric(Full_800$V201233), # Numeric
  Age = as.numeric(Full_800$V201507x) # Numeric
)

# Check the number of documents
n_documents <- length(topic_dfm_stm$documents)
# Check the number of rows in metadata
n_metadata <- nrow(meta_data)

# Print out the counts to see the mismatch
cat("Number of documents:", n_documents, "\n")
cat("Number of metadata entries:", n_metadata, "\n")

# Meta-data correction
meta_data <- head(meta_data, -1)

# Fit the STM model with covariates
fit_stm_34 <- stm(documents = topic_dfm_stm$documents, vocab = topic_dfm_stm$vocab, K = 34,prevalence =~ PartyId + Education + Ideology + GovTrust,
max.em.its = 1000000, data = meta_data, init.type = "Spectral", verbose = TRUE)

# Label topics
labelTopics(fit_stm_34)
```

## Model A at 38

```{r}
# Fit the STM model with covariates
fit_stm_38 <- stm(documents = topic_dfm_stm$documents, vocab = topic_dfm_stm$vocab, K = 38,prevalence =~ PartyId + Education + Ideology + GovTrust,
max.em.its = 1000000, data = meta_data, init.type = "Spectral", verbose = TRUE)

# Label topics
labelTopics(fit_stm_38)
```

## Preprossesing for Model B

```{r}
#Generate Dem Likes Sample of 200
anes_data_full_B <- read_excel("anes_2020_4 (1).xlsx", sheet = 2)


# Sample 200 responses 
Full_16677 <- anes_data_full_B

# Load necessary libraries
library(dplyr)
library(tm)
library(stm)
library(tidytext)
library(quanteda)
library(tidyr)

# Assuming the data frame is named Full_800 and is already loaded into R
# and it has the columns Dem_Likes, Dem_Dislikes, Rep_Likes, Rep_Dislikes

# Combine the text columns into a single text vector
# Uniting all text responses into one column for each row
Full_16677_combined <- Full_16677

# corpus object with the text data
corp_quanteda <- corpus(Full_16677_combined$Responses)

# Tokenization and preprocessing
preprocessed_text_data_b <- tokens(corp_quanteda, 
                                 remove_numbers = TRUE, 
                                 remove_punct = TRUE,
                                 remove_symbols = TRUE) %>%
  tokens_remove(stopwords("en")) %>%
  tokens_wordstem(language = "english") %>%
  tokens_tolower() %>%
  tokens_ngrams(1)

# Create the document-feature matrix (DFM)
topic_dfm_b <- dfm(preprocessed_text_data_b) 

# Convert the DFM to the stm format
topic_dfm_stm_b <- quanteda::convert(topic_dfm_b, to = "stm")

# Extract the covariates
meta_data_b <- data.frame(
  PartyId = as.factor(Full_16677$V201228), # Factor
  Education = as.factor(Full_16677$V201510), # Factor
  Ideology = as.numeric(Full_16677$V201201), # Numeric
  GovTrust = as.numeric(Full_16677$V201233), # Numeric
  Age = as.numeric(Full_16677$V201507x) # Numeric
)

# Check the number of documents
n_documents <- length(topic_dfm_stm_b$documents)
# Check the number of rows in metadata
n_metadata <- nrow(meta_data_b)

# Print out the counts to see the mismatch
cat("Number of documents:", n_documents, "\n")
cat("Number of metadata entries:", n_metadata, "\n")

# Meta-data correction
meta_data_b <- head(meta_data_b, -4)
```

## Finding K (Model B)

```{r eval=FALSE, include=FALSE}
# narrowed results
result_narrowed_b <- searchK(documents = topic_dfm_stm_b$documents, vocab = topic_dfm_stm_b$vocab, K = 30:40)


# You can plot the results to assess the model fit across different numbers of topics
plot(result_narrowed_b, type = "line", ylim = c(0, max(result$heldout)))

# Plot the results
plot(result_narrowed_b, metric = "heldout")
plot(result_narrowed_b, metric = "semanticcoherence")
plot(result_narrowed_b, metric = "residual")

```

## Model B at 32

```{r}
# STM Model
fit_stm_32_b <- stm(documents =
topic_dfm_stm_b$documents, vocab = topic_dfm_stm_b$vocab, K = 32, prevalence
=~ PartyId + Education + Ideology + GovTrust, max.em.its = 1000000,
data = meta_data_b, init.type = "Spectral", verbose = TRUE)

# Label topics

labelTopics(fit_stm_32_b)
```


## Model B at 35

```{r}
# STM Model
fit_stm_35_b <- stm(documents =
topic_dfm_stm_b$documents, vocab = topic_dfm_stm_b$vocab, K = 35,prevalence
=~ PartyId + Education + Ideology + GovTrust, max.em.its = 1000000,
data = meta_data_b, init.type = "Spectral", verbose = TRUE)

# Label topics

labelTopics(fit_stm_35_b)
```