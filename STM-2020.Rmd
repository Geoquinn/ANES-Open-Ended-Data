---
title: "STM_Outputs"
author: "George D. Quinn"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 200 Randomly Generated Responses

## for all 4 Questions

```{r}
library(readxl)
library(dplyr)

#Generate Dem Likes Sample of 200
anes_data_dem_likes <- read_excel("anes_2020_4.xlsx", sheet = 1)

# Filter out '-1' and '-9' responses
valid_responses_DL <- filter(anes_data_dem_likes, V201107 != "-1", V201107 != "-9")

# Sample 200 responses (or fewer if there are not enough valid responses)
Dem_Like_200 <- sample_n(valid_responses_DL, size = min(200, nrow(valid_responses_DL)), replace = FALSE)

# View the sampled data
print(Dem_Like_200)

#Generate Dem Dislikes Sample of 200

anes_data_dem_dislikes <- read_excel("anes_2020_4.xlsx", sheet = 2)

# Filter out '-1' and '-9' responses
valid_responses_DDL <- filter(anes_data_dem_dislikes, V201109 != "-1", V201109 != "-9")

# Sample 200 responses (or fewer if there are not enough valid responses)
Dem_Dislike_200 <- sample_n(valid_responses_DDL, size = min(200, nrow(valid_responses_DDL)), replace = FALSE)

# View the sampled data
print(Dem_Dislike_200)

#Generate Rep Likes Sample of 200
anes_data_rep_likes <- read_excel("anes_2020_4.xlsx", sheet = 3)

# Filter out '-1' and '-9' responses
valid_responses_RL <- filter(anes_data_rep_likes, V201111 != "-1", V201111 != "-9")

# Sample 200 responses (or fewer if there are not enough valid responses)
Rep_Like_200 <- sample_n(valid_responses_RL, size = min(200, nrow(valid_responses_RL)), replace = FALSE)

# View the sampled data
print(Rep_Like_200)

#Generate Rep Dislikes Sample of 200

anes_data_rep_dislikes <- read_excel("anes_2020_4.xlsx", sheet = 4)

# Filter out '-1' and '-9' responses
valid_responses_RDL <- filter(anes_data_rep_dislikes, V201113 != "-1", V201113 != "-9")

# Sample 200 responses (or fewer if there are not enough valid responses)
Rep_Dislike_200 <- sample_n(valid_responses_RDL, size = min(200, nrow(valid_responses_RDL)), replace = FALSE)

# View the sampled data
print(Rep_Dislike_200)
```

## Building STM Model with Covariates (Dem Likes)

```{r}
library(stm)
library(quanteda)
library(wordcloud)
library(ggplot2)

# corpus object with the text data
corp_quanteda <- corpus(Dem_Like_200$V201107)

# Tokenization and preprocessing
preprocessed_text_data <- tokens(corpus(Dem_Like_200$V201107), 
              remove_numbers = TRUE, 
              remove_punct = TRUE,
              remove_symbols = TRUE) %>%
  tokens_remove(stopwords(source = "snowball")) %>%
  tokens_wordstem(language = "english") %>%
  tokens_tolower() %>%
  tokens_ngrams(1)

# Create the document-feature matrix (DFM)
topic_dfm <- dfm(preprocessed_text_data) 

# Convert the DFM to the stm format
topic_dfm_stm <- quanteda::convert(topic_dfm, to = "stm")

# Extract the covariates
meta_data <- data.frame(
  PartyId = as.factor(Dem_Like_200$V201228), # Factor
  Education = as.factor(Dem_Like_200$V201510), # Factor
  Ideology = as.numeric(Dem_Like_200$V201201), # Numeric
  GovTrust = as.numeric(Dem_Like_200$V201233), # Numeric
  Age = as.numeric(Dem_Like_200$V201507x) # Numeric
)

# Fit the STM model with covariates
fit_stm <- stm(documents = topic_dfm_stm$documents, vocab = topic_dfm_stm$vocab, K = 35,
               prevalence =~ PartyId + Education + Ideology + GovTrust + Age,
               max.em.its = 1000, data = meta_data, init.type = "Spectral", verbose = TRUE)

print(topics_labels)
```

## Data Visualization of Output (Dem Likes

## Find Thoughts (Dem Likes)

```{r}
print(top_thoughts)
```

## Word Clouds (Dem Likes)

```{R}
library(stm)
library(ggplot2)

# Generate word clouds for each topic individually
for(topic in 1:35) {
  cloud(fit_stm, topic = topic)
  title(paste("Word Cloud for Topic", topic))
}
```

## Effects of Covariates (Dem Likes)

```{r}
# Get the summary of the estimated effects
summary_estEffoff 
```
